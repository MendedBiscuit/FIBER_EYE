project: FIBER_EYE
data_version: 1.0

naming_conventions:
  raw_input:
    pattern: "{sample_id}_{type / channel_key}.png"
    example: "1_A.png, 1_B.png"
    channel_keys:
      A: Ambient Light
      B: Blue LED
      G: Green LED
      R: Red LED
    types:
      M: Mask
      P: Prediction

  tiled_png:
    pattern: "{sample_id}_{y_location}_{x_location}_{channel_key}.png"
    usage: input of CLASSIC_CV
  
  tiled_training_array:
    pattern: "{sample_id}_{y_location}_{x_location}_multimodal.npz"
    usage: training data
    shape: [Height, Width, 15]

  tiled_masks:
    pattern: "{sample_id}_{x_location}_{y_location}_multimodal.png"
    usage: tiled training masks

array_channels:
  channels:
    0-2: Ambient (BGR)
    3-5: Blue Light (BGR)
    6-8: Green Light (BGR)
    9-11: Red Light (BGR)
    12-15: Local RMS Texture Map

paths:

  preprocessing: 

    training_data: "./1_PREPROCESSING/IN_PREPROCESS_TRAIN/IN_TRAIN_DATA/"
    prediction_data: "./1_PREPROCESSING/IN_PREPROCESS_TRAIN/IN_PREDICT_DATA/"
    
    json_mask: "./1_PREPROCESSING/IN_PREPROCESS_TRAIN/mask_data.json"
    png_masks: "./1_PREPROCESSING/IN_PREPROCESS_TRAIN/MASK_PNG"
  
  processing:

    classic_cv:

      input: "./2_PROCESSING/CLASSIC_CV/IN_CV/"
      output: "./3_POSTPROCESSING/OUT_CV/"

    rf:

      model: "./2_PROCESSING/RF/model/rf_woodchip_model.joblib"

      output: "./3_POSTPROCESSING/OUT_RF/"

    unet:

      model: "./1/353ddf8fc5d6464ba39d04e019504093/checkpoints/epoch=49-step=450.ckpt"

      output: "./3_POSTPROCESSING/OUT_UNET/"

    data:

        input:

          train_array: "./2_PROCESSING/DATA/TRAIN/TRAIN_ARRAY/"
          train_mask: "./2_PROCESSING/DATA/TRAIN/TRAIN_MASK/" 

          validation_array: "./2_PROCESSING/DATA/VALID/VALID_ARRAY/"
          validation_mask: "./2_PROCESSING/DATA/VALID/VALID_MASK/"

          prediction_array: "./2_PROCESSING/DATA/PREDICT_ARRAY/"
      
important_variables:
  tile_size: 512
  stride: 256


  
