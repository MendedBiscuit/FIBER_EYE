project: FIBER_EYE
data_version: 1.0

naming_conventions:
  raw_input:
    pattern: "{sample_id}_{type / channel_key}.png"
    example: "1_A.png, 1_B.png"
    channel_keys:
      A: Ambient Light
      B: Blue LED
      G: Green LED
      R: Red LED
    types:
      M: Mask
      P: Prediction

  preprocessed_output:
    pattern: "{sample_id}_{y_location}_{x_location}_{channel_key}.png"
    description: Individual images after intensity normalization and CLAHE.
    folder: "./2_PROCESSING/CLASSIC_CV/IN_CV"

  training_arrays:
    pattern: "{sample_id}_{y_location}_{x_location}_multimodal.npz"
    description: 13-D array with all light data, chopped regions.
    folder: "./2_PROCESSING/UNET/IN_UNET/TRAIN/TRAIN_ARRAY"
    format: NumPy Array (Float32)
    shape: [Height, Width, 13]

  masks:
    pattern: "{sample_id}_{x_location}_{y_location}_multimodal.png"
    description: Mask for each array, also chopped into regions.
    folder: "./2_PROCESSING/UNET/IN_UNET/TRAIN/TRAIN_MASK"
tensor_stack_definition:
  channels:
    0-2: Ambient (BGR)
    3-5: Blue Light (BGR)
    6-8: Green Light (BGR)
    9-11: Red Light (BGR)
    12: Local RMS Texture Map

preprocessing_logic:
  normalization: Gaussian light correction (129x129 kernel)
  enhancement: CLAHE